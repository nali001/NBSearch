{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2FGA7CEvWSy6"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import gensim\n",
        "import json\n",
        "import pandas as pd\n",
        "import pickle as tastes_good\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import tokenize, io\n",
        "\n",
        "from keras.models import load_model, Model\n",
        "from end2end.seq2seq import load_text_processor, load_decoder_inputs, load_encoder_inputs, Seq2Seq_Inference "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbrqM0vfqQKD"
      },
      "source": [
        "<h3> 1. Load training file</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8wu0RwjWSzO",
        "outputId": "9f8199a9-5b26-48d5-df56-1013fedf42aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of vocabulary for data/cell_pp.dpkl: 8,002\n",
            "Size of vocabulary for data/comments_pp.dpkl: 4,502\n"
          ]
        }
      ],
      "source": [
        "seq2seq_Model = tf.keras.models.load_model('bilstm_seq2seq_model.h5')\n",
        "num_encoder_tokens, funct_pp = load_text_processor('data/cell_pp.dpkl')\n",
        "num_decoder_tokens, comts_pp = load_text_processor('data/comments_pp.dpkl')\n",
        "seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=funct_pp,\n",
        "                                 decoder_preprocessor=comts_pp,\n",
        "                                 seq2seq_model=seq2seq_Model, model_option='bilstm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TEBx6g8jWSzP"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "df_nb = pd.read_csv('data/csv/notebooks_sample.csv', nrows = 20)\n",
        "df_nb = df_nb.drop(columns=['html_url', 'max_filesize', 'min_filesize', 'query_page', 'path', 'name', 'repo_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29n3ZiM-WSzQ"
      },
      "source": [
        "<h3>Find how many cells a notebook has, and then append a new column to the dataframe</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "77LssO5kWSzQ"
      },
      "outputs": [],
      "source": [
        "def get_num_cells(nb_id):\n",
        "    \n",
        "    nb_name = 'data/notebooks/nb_' + str(nb_id) + '.ipynb'\n",
        "    \n",
        "    with open(nb_name) as nb_file:\n",
        "        \n",
        "        try:\n",
        "            # get the nb as a JSON file\n",
        "            data = json.load(nb_file)\n",
        "            if isinstance(data, dict): \n",
        "                keys = data.keys()\n",
        "            else:\n",
        "                keys = []\n",
        "            \n",
        "            # get the number of cells\n",
        "            if 'cells' in keys:\n",
        "                return len(data['cells'])\n",
        "            elif 'worksheets' in keys:\n",
        "                num_cells = 0\n",
        "                for w in data['worksheets']:\n",
        "                    num_cells += len(w['cells'])\n",
        "                return num_cells\n",
        "        \n",
        "        except:\n",
        "            return None\n",
        "        \n",
        "        \n",
        "df_nb['num_cells'] = df_nb['nb_id'].apply(get_num_cells)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv_K99kGWSzR"
      },
      "source": [
        "<h3>Only keep notebooks with more than 0 cells. We do not even consider notebooks that have no cells</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4q6OY5D9WSzR"
      },
      "outputs": [],
      "source": [
        "df_nb = df_nb.query(\"num_cells > 0\")\n",
        "df_nb = df_nb.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2BQxsJYWSzR"
      },
      "source": [
        "<h3>Append a new column -- 'cells'. A list of [cell_type, cell_content]</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "j1biLmDYWSzR"
      },
      "outputs": [],
      "source": [
        "def keep_code_and_markdown(row):\n",
        "    if row.get('cell_type') == \"code\" or row.get('cell_type') == \"markdown\":\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def keep_source_code(row):\n",
        "    if row.get('source') == None:\n",
        "        return [row.get('cell_type'), row.get('input')]\n",
        "    return [row.get('cell_type'), row.get('source')]\n",
        "\n",
        "\n",
        "# is the markdown cells helpful?\n",
        "def get_codes(nb_id):\n",
        "    \n",
        "    nb_name = 'data/notebooks/nb_' + str(nb_id) + '.ipynb'\n",
        "    \n",
        "    with open(nb_name) as nb_file:\n",
        "        \n",
        "        try:\n",
        "            # get the nb as a JSON file\n",
        "            data = json.load(nb_file)\n",
        "            if isinstance(data, dict): \n",
        "                keys = data.keys()\n",
        "            else:\n",
        "                keys = []\n",
        "            \n",
        "            # get the number of cells\n",
        "            if 'cells' in keys:\n",
        "                iterable = data['cells']\n",
        "                itor = list(filter(keep_code_and_markdown, iterable))\n",
        "                itor = list(map(keep_source_code, itor))\n",
        "                return itor\n",
        "            elif 'worksheets' in keys:\n",
        "                cells = []\n",
        "                for w in data['worksheets']:\n",
        "                    cells.append(w['cells'])\n",
        "                flattened_list = [y for x in cells for y in x]\n",
        "                itor = list(filter(keep_code_and_markdown, flattened_list))\n",
        "                itor = list(map(keep_source_code, itor))\n",
        "                return itor\n",
        "        \n",
        "        except:\n",
        "            return None\n",
        "        \n",
        "df_nb['cells'] = df_nb['nb_id'].apply(get_codes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcFCRazpWSzS"
      },
      "source": [
        "<h3>Remove notebooks with cells == None</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4qx0sb6TWSzT"
      },
      "outputs": [],
      "source": [
        "df_nb = df_nb[df_nb.cells != None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwv8m_5GWSzU"
      },
      "source": [
        "<h3>Drop the column num_cells since it's not useful anymore.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hm7uBXQ8WSzV"
      },
      "outputs": [],
      "source": [
        "df_nb = df_nb.drop(columns=['num_cells'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvJwgH3qWSzV"
      },
      "source": [
        "<h3>Expand notebooks based on column 'cells'</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OveYJ1yAWSzW"
      },
      "outputs": [],
      "source": [
        "df_nb = df_nb.explode('cells').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48h7XEXdWSzW"
      },
      "source": [
        "<h3>Remove cells that has nothing inside.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "0G43C_RFWSzW"
      },
      "outputs": [],
      "source": [
        "df_nb = df_nb[df_nb.cells != None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lXEIhqJWSzX"
      },
      "source": [
        "<h3>Append new columns 'markdown_cell' and 'code_cell' to the dataframe.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1dfJ_UTaWSzX"
      },
      "outputs": [],
      "source": [
        "def get_codecell(a_cell):\n",
        "    try:\n",
        "        if a_cell[0] == 'markdown':\n",
        "            return None\n",
        "        return a_cell[1]\n",
        "    except:\n",
        "        return None\n",
        "def get_markdowncell(a_cell):\n",
        "    try:\n",
        "        if a_cell[0] == 'code':\n",
        "            return None\n",
        "        return a_cell[1]\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8ojIyLwWSzX"
      },
      "source": [
        "<h3>For 'markdown_cell' column, it contains content if the current row is a markdown cell, o/w None.</h3>\n",
        "<h3>Similar for the 'code_cell' column.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "e8EqO5hDWSzY"
      },
      "outputs": [],
      "source": [
        "df_nb['markdown_cell'] = df_nb['cells'].apply(get_markdowncell)\n",
        "df_nb['code_cell'] = df_nb['cells'].apply(get_codecell)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PEJEcdGWSza"
      },
      "source": [
        "<h3>2. convert code to list of vectors</h3>\n",
        "\n",
        "<h3>Add new column 'code_cell_no_comments' which does not have comments, just source code of each code cell.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "v3s2P9J7WSza"
      },
      "outputs": [],
      "source": [
        "# get pure code \n",
        "def remove_comments(lst):\n",
        "    try:\n",
        "        if lst == None:\n",
        "            return None\n",
        "        elif lst == []:\n",
        "            return ''\n",
        "        the_whole_cell = ''\n",
        "    \n",
        "        for li in lst:\n",
        "            the_whole_cell += li\n",
        "       \n",
        "        buf = io.StringIO(the_whole_cell)\n",
        "        ans = ''\n",
        "        for line in tokenize.generate_tokens(buf.readline):\n",
        "            if line.type != tokenize.COMMENT:\n",
        "                ans += line.string + ' '\n",
        "        return ans\n",
        "    except:\n",
        "        return 'Syntax_error'\n",
        "    \n",
        "df_nb['code_cell_no_comments'] = df_nb['code_cell'].apply(remove_comments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w9KMQr9WSza"
      },
      "source": [
        "<h3>This cell contains function definition which will be used later for extracting comments from code_cell </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_jtS2VrhWSzb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# just a way to detect if we run into a scenario mentioned above\n",
        "def is_valid_python(code):\n",
        "    try:\n",
        "        ast.parse(code)\n",
        "    except SyntaxError:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# Use list.append in getting comments... but string concatenation in removing comments\n",
        "# Reasonable, need to check English comments again, so string concatenation may not work\n",
        "def get_comments(lst):\n",
        "    try:\n",
        "        if lst == None:\n",
        "            return None\n",
        "        elif lst == []:\n",
        "            return []\n",
        "        the_whole_cell = ''\n",
        "        for li in lst:\n",
        "            the_whole_cell += li\n",
        "       \n",
        "        buf = io.StringIO(the_whole_cell)\n",
        "        ans = []\n",
        "        for line in tokenize.generate_tokens(buf.readline):\n",
        "            if line.type == tokenize.COMMENT:\n",
        "                # check if you have things like \"#for variable in field.getchildren():\"\n",
        "                if (is_valid_python(line.string.strip(\"#\").strip(\" \").strip(\"#\"))):\n",
        "                    continue\n",
        "                else:\n",
        "                    ans.append(line.string)\n",
        "        return ans\n",
        "    except:\n",
        "        # your code has syntax errors...\n",
        "        return \"Syntax_error\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6ByIMS3WSzb"
      },
      "source": [
        "<h3>Remove cells that has syntax error in code...</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "bV9NCrEkWSzb"
      },
      "outputs": [],
      "source": [
        "# drop those rows have \"Syntax_error,srsly?\"\n",
        "df_nb = df_nb[df_nb.code_cell_no_comments != 'Syntax_error']\n",
        "df_nb = df_nb.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWWCVYs_WSzc"
      },
      "source": [
        "<h3>Extract comments from cells</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "SRpgAHNaWSzc"
      },
      "outputs": [],
      "source": [
        "df_nb['code_cell_comments'] = df_nb['code_cell'].apply(get_comments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pf6dW8xWSzd"
      },
      "source": [
        "<h3>Also removes cells with syntax error.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "yGMBqaFuWSzd"
      },
      "outputs": [],
      "source": [
        "df_nb = df_nb[df_nb.code_cell_comments != 'Syntax_error']\n",
        "df_nb = df_nb.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3API-PsXWSzd"
      },
      "source": [
        "<h3>Remove comments with non-ascii characters.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "k86JIKcMWSzg"
      },
      "outputs": [],
      "source": [
        "def is_English(s):\n",
        "    try:\n",
        "        s.encode(encoding='utf-8').decode('ascii')\n",
        "    except UnicodeDecodeError:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def remove_non_ascii_comments(lst):\n",
        "    if lst == None:\n",
        "        return None\n",
        "    ans = []\n",
        "    for cmt in lst:\n",
        "        if (is_English(cmt)):\n",
        "            ans.append(cmt)\n",
        "    return ans\n",
        "\n",
        "df_nb['code_cell_comments'] = df_nb['code_cell_comments'].apply(remove_non_ascii_comments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaIKw-gFng87"
      },
      "source": [
        "<h3> Concatenate comments into a new column 'conc_comment' </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wN4YXjzVnhkQ"
      },
      "outputs": [],
      "source": [
        "def concatenate_valid_comments(lst):\n",
        "    if lst == None:\n",
        "        return None\n",
        "    if lst == []:\n",
        "        return ''\n",
        "    ans = ''\n",
        "    for cmt in lst:\n",
        "        ans += cmt + ' '\n",
        "    return ans\n",
        "\n",
        "df_nb['conc_comment'] = df_nb['code_cell_comments'].apply(concatenate_valid_comments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NxzER14nwg7"
      },
      "source": [
        "<h3>Remove cells = None</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "c439XJAmntSY"
      },
      "outputs": [],
      "source": [
        "realdf = df_nb[df_nb['cells'].map(type) != float].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35Bg9xQtn3fm"
      },
      "source": [
        "<h3>Remove cells = [Mkd/code, None]</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OPYyPXoDn3qn"
      },
      "outputs": [],
      "source": [
        "def check_useless_cell(a_cell):\n",
        "    if a_cell != None:\n",
        "        if a_cell[1] == None:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "actualdf = realdf[realdf['cells'].map(check_useless_cell) != True].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdfneNsZoB08"
      },
      "source": [
        "<h3>Remove code_cell_no_comments = \"\"</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vws7GWUgn_pV"
      },
      "outputs": [],
      "source": [
        "def check_empty_code(a_cell):\n",
        "    if a_cell == '':\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "actualdf = actualdf[actualdf['code_cell_no_comments'].map(check_empty_code) != True].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFoDBDgSWSzh"
      },
      "source": [
        "<h3>emb_vecs_code_middle is a list contains all code descriptors.</h3>\n",
        "\n",
        "<h3>If the current cell is markdown, emb_vecs_code_middle will append a '0' to it\n",
        "<h3>If the current code cell contains original comment, then use the original</h3>\n",
        "<h3>If the current code cell did not have descriptor, use the predicted one.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u7YGcp4WSzi",
        "outputId": "2bd8d6ad-c4a3-436a-d919-0cb1f271f9ee",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "210"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_vecs_code_middle = []\n",
        "for index, row in actualdf.iterrows():\n",
        "    if row['code_cell_no_comments'] == None:\n",
        "        # markdown cell\n",
        "        emb_vecs_code_middle.append(0)\n",
        "    else:\n",
        "        if row['conc_comment'] != '':\n",
        "            emb_vecs_code_middle.append(row['conc_comment'])\n",
        "        else:\n",
        "            try:\n",
        "                emb_vecs_code_middle.append((seq2seq_inf.generate_comments(row['code_cell_no_comments']))[1])\n",
        "            except:\n",
        "                # change this to 0????\n",
        "                emb_vecs_code_middle.append('ERR_predict_false')\n",
        "emb_vecs_code_middle.count('ERR_predict_false')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "GLGxYBakWSzi"
      },
      "outputs": [],
      "source": [
        "with open('data/all_code_middle_embeddings.txt', 'wb') as file:\n",
        "    tastes_good.dump(emb_vecs_code_middle, file)\n",
        "the_lan_model = gensim.models.doc2vec.Doc2Vec.load('my_model.doc2vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zorSh99bWSzj"
      },
      "source": [
        "<h3>Convert emb_vecs_code_middle into list of vectors.</h3>\n",
        "<h3>If emb_vecs_code_middle[i] == 0, then emb_vecs_code[i] = 0.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IwF-BLcWSzj",
        "outputId": "d8d7bae0-2e8a-44c7-a649-65fa3a135560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 705 ms, sys: 3.84 ms, total: 709 ms\n",
            "Wall time: 722 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "emb_vecs_code = []\n",
        "for pred in emb_vecs_code_middle:\n",
        "    try:\n",
        "        if pred == 0:\n",
        "            emb_vecs_code.append(0)\n",
        "        else:\n",
        "            emb_vecs_code.append(the_lan_model.infer_vector(gensim.utils.simple_preprocess(pred)))\n",
        "    except:\n",
        "        print(pred)\n",
        "        break\n",
        "with open('data/all_code_embeddings.txt', 'wb') as file:\n",
        "    tastes_good.dump(emb_vecs_code, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDkiYqgDWSzl"
      },
      "source": [
        "<h3>3. convert mkd to list of vectors</h3>\n",
        "<h3>If the current cell is not markdown, append 0 to it.</h3>\n",
        "<h3>Else use our doc2vec model to predict the vector.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "I1SqXdNVWSzm"
      },
      "outputs": [],
      "source": [
        "emb_vecs_mkd = []\n",
        "for index, row in actualdf.iterrows():\n",
        "    if row['markdown_cell'] == None:\n",
        "        emb_vecs_mkd.append(0)\n",
        "    elif row['markdown_cell'] == []:\n",
        "        emb_vecs_mkd.append(the_lan_model.infer_vector(gensim.utils.simple_preprocess('')))\n",
        "    else:\n",
        "        emb_vecs_mkd.append(the_lan_model.infer_vector(gensim.utils.simple_preprocess(row['markdown_cell'][0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "iR3BzNwFWSzn"
      },
      "outputs": [],
      "source": [
        "with open('data/all_markdown_embeddings.txt', 'wb') as file:\n",
        "    tastes_good.dump(emb_vecs_mkd, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSd5OPk2WSzn"
      },
      "source": [
        "<h3>4. store the relationships</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhVI-usjWSzn"
      },
      "source": [
        "<h3>Create a dictionary which stores information about contribution of markdown cells to code cells</h3>\n",
        "<h3>Specifically, key : value pairs => markdown_cell_index : [array of indexes that from code cells impacted by the markdown cell]</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "LT8IJShBWSzo"
      },
      "outputs": [],
      "source": [
        "dict_relationships = {}\n",
        "# helper function \n",
        "def find_contribution(index, max_row):\n",
        "    the_id = actualdf.iloc[index]['nb_id']\n",
        "    arr = []\n",
        "    loop = True\n",
        "    curr_index = index + 1\n",
        "    while curr_index < max_row:\n",
        "        if actualdf.iloc[curr_index]['nb_id'] == the_id:\n",
        "            # same notebook\n",
        "            if actualdf.iloc[curr_index]['markdown_cell'] == None:\n",
        "                # A consequtive code cell\n",
        "                arr.append(curr_index)\n",
        "                curr_index = curr_index + 1\n",
        "            else:\n",
        "                # same nb but a markdown cell, time to stop the loop\n",
        "                break\n",
        "        else:\n",
        "            # different nb, time to stop\n",
        "            break\n",
        "        \n",
        "    return arr\n",
        "    \n",
        "total_rows = actualdf.shape[0]\n",
        "for index, row in actualdf.iterrows():\n",
        "    if row['markdown_cell'] != None:\n",
        "        arr = find_contribution(index, total_rows)\n",
        "        dict_relationships[str(index)] = arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCQwoPzdWSzo"
      },
      "source": [
        "<h3>After applying the find_contribution function.</h3>\n",
        "<h3>E.g. index 0 is a markdown cell, it has impact on code cells from 1 to 27</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD0koEGcWSzo",
        "outputId": "34b0142e-84aa-499d-cf47-4cc7f38e8671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'0': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], '28': [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], '45': [], '46': [], '47': [48, 49], '50': [], '51': [], '52': [53, 54, 55, 56, 57, 58, 59], '60': [61, 62, 63, 64], '65': [], '66': [], '67': [68, 69, 70, 71, 72, 73, 74], '75': [76, 77, 78, 79, 80, 81, 82], '83': [84, 85, 86, 87], '88': [], '106': [107, 108, 109, 110, 111, 112], '113': [114, 115, 116, 117, 118, 119, 120, 121, 122], '123': [124, 125], '126': [127, 128, 129, 130], '131': [132, 133, 134], '135': [], '136': [], '137': [138], '139': [140, 141, 142], '143': [144, 145], '146': [], '147': [148], '149': [150], '151': [152, 153], '154': [155], '156': [157], '158': [159], '160': [161], '162': [163, 164], '165': [166, 167], '168': [169], '170': [171], '172': [173], '174': [175], '176': [177, 178], '179': [180], '181': [182], '183': [184], '185': [186], '187': [188, 189], '190': [191, 192], '193': [], '194': [], '195': [], '196': [197], '198': [199], '200': [201], '202': [203], '204': [205], '206': [207], '208': [], '209': [], '210': [211, 212, 213, 214, 215, 216], '217': [218], '219': [220], '221': [222], '223': [224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238], '239': [240], '241': [242], '243': [244], '245': [246, 247, 248, 249, 250, 251, 252], '253': [254], '255': [256], '257': [258], '259': [260], '261': [262], '263': [], '264': [265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275], '288': [289, 290, 291, 292, 293, 294], '336': [337, 338], '339': [340], '341': [342], '343': [344], '345': [346, 347], '348': [349, 350], '351': [352], '353': [354], '355': [356], '357': [358], '359': [360, 361], '362': [], '363': [364, 365], '366': [], '367': [368, 369, 370, 371, 372, 373, 374], '375': [], '376': [377], '378': [], '379': [380], '381': [382], '383': [384, 385], '386': [387, 388, 389, 390], '391': [392], '393': [], '394': [395, 396], '397': [398, 399], '400': [], '413': [], '414': [], '415': [], '416': [], '417': [], '418': [419, 420, 421], '422': [423], '424': [425], '426': [427], '428': [429], '430': [431, 432], '433': [434, 435, 436, 437], '486': [487], '488': [489], '490': [491], '492': [493], '494': [], '495': [496], '497': [498], '499': [500], '501': [502]}\n"
          ]
        }
      ],
      "source": [
        "print(dict_relationships)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfViXfNnWSzq"
      },
      "source": [
        "<h3>Testing cell.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfFHwxabWSzq",
        "outputId": "c540857e-f4ae-4580-fa75-3cdd7035bd30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.015332  , -0.01260937], dtype=float32)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "the_lan_model.infer_vector(gensim.utils.simple_preprocess('Test'))[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1pl8sjfWSzr"
      },
      "source": [
        "<h3>Create an array which has length = number of rows in our dataframe, i.e. each element is representing a cell</h3>\n",
        "<h3>An element is None if the corresponding cell is markdown, o/w index of the markdown has impact on me.</h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FNtVdo8FWSzr"
      },
      "outputs": [],
      "source": [
        "relationship_arr = [None] * len(emb_vecs_code)\n",
        "for dic in dict_relationships:\n",
        "    child_code_arr = dict_relationships[str(dic)]\n",
        "    for indx in child_code_arr:\n",
        "        relationship_arr[indx] = int(dic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-WO2fAdWSzr"
      },
      "source": [
        "<h3>For example, remember previously, we said index 0 contains a markdown cell, so relationship_arr[0] = None, and all code cells from 1 to 27 are impacted by cell 0.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTPGgVBPWSzs",
        "outputId": "6b6a0229-a296-4242-a462-2e537a368500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, None, None, None, 47, 47, None, None, None, 52, 52, 52, 52, 52, 52, 52, None, 60, 60, 60, 60, None, None, None, 67, 67, 67, 67, 67, 67, 67, None, 75, 75, 75, 75, 75, 75, 75, None, 83, 83, 83, 83, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 106, 106, 106, 106, 106, 106, None, 113, 113, 113, 113, 113, 113, 113, 113, 113, None, 123, 123, None, 126, 126, 126, 126, None, 131, 131, 131, None, None, None, 137, None, 139, 139, 139, None, 143, 143, None, None, 147, None, 149, None, 151, 151, None, 154, None, 156, None, 158, None, 160, None, 162, 162, None, 165, 165, None, 168, None, 170, None, 172, None, 174, None, 176, 176, None, 179, None, 181, None, 183, None, 185, None, 187, 187, None, 190, 190, None, None, None, None, 196, None, 198, None, 200, None, 202, None, 204, None, 206, None, None, None, 210, 210, 210, 210, 210, 210, None, 217, None, 219, None, 221, None, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, 223, None, 239, None, 241, None, 243, None, 245, 245, 245, 245, 245, 245, 245, None, 253, None, 255, None, 257, None, 259, None, 261, None, None, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, None, None, None, None, None, None, None, None, None, None, None, None, None, 288, 288, 288, 288, 288, 288, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 336, 336, None, 339, None, 341, None, 343, None, 345, 345, None, 348, 348, None, 351, None, 353, None, 355, None, 357, None, 359, 359, None, None, 363, 363, None, None, 367, 367, 367, 367, 367, 367, 367, None, None, 376, None, None, 379, None, 381, None, 383, 383, None, 386, 386, 386, 386, None, 391, None, None, 394, 394, None, 397, 397, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 418, 418, 418, None, 422, None, 424, None, 426, None, 428, None, 430, 430, None, 433, 433, 433, 433, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 486, None, 488, None, 490, None, 492, None, None, 495, None, 497, None, 499, None, 501]\n"
          ]
        }
      ],
      "source": [
        "print(relationship_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "HDJU8UBuWSzs"
      },
      "outputs": [],
      "source": [
        "with open(\"data/child_relationships.txt\", \"wb\") as fp:\n",
        "    tastes_good.dump(relationship_arr, fp)\n",
        "actualdf.to_csv('data/stored_df.csv', index=False)\n",
        "with open(\"data/dict.pkl\", \"wb\") as fp:\n",
        "    tastes_good.dump(dict_relationships, fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmqldcRKWSzt"
      },
      "source": [
        "<h3>End of 1-4 steps (above)\n",
        "\n",
        "This section is to make sure our lists do not contain dangerous values\n",
        "</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "l87zM7tnWSzt"
      },
      "outputs": [],
      "source": [
        "# clear markdown\n",
        "emb_vecs_code_no_zero = []\n",
        "for vec in emb_vecs_code:\n",
        "    if type(vec) != int:\n",
        "        emb_vecs_code_no_zero.append(vec)\n",
        "        \n",
        "emb_vecs_mkd_no_zero = []\n",
        "for vec in emb_vecs_mkd:\n",
        "    if type(vec) != int:\n",
        "        emb_vecs_mkd_no_zero.append(vec)     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "J_lj25LXWSzt"
      },
      "outputs": [],
      "source": [
        "# clear markdown\n",
        "df_nb_no_mkd = actualdf[actualdf['code_cell_no_comments'].map(type) != type(None)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROxDooMMWSzu",
        "outputId": "ca3520de-e775-47f8-9e14-ac015ff15946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "counter_aa = 0\n",
        "for index, row in actualdf.iterrows():\n",
        "    if row['code_cell_no_comments'] == '':\n",
        "        counter_aa = counter_aa + 1\n",
        "print(counter_aa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zfq4k1oGWSzu",
        "outputId": "aeef9bd7-c278-4325-f77f-8044bc19594a",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[0,99] = 1737 is not in [0, 547)\n\t [[node Encoder-Model/Cell-Word-Embedding/embedding_lookup (defined at home/na/codes/NBSearch/end2end/seq2seq.py:223) ]]\n\t [[Encoder-Model/Cell-Word-Embedding/embedding_lookup/_6]]\n  (1) Invalid argument:  indices[0,99] = 1737 is not in [0, 547)\n\t [[node Encoder-Model/Cell-Word-Embedding/embedding_lookup (defined at home/na/codes/NBSearch/end2end/seq2seq.py:223) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_164121]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Encoder-Model/Cell-Word-Embedding/embedding_lookup:\n Encoder-Model/Cell-Word-Embedding/embedding_lookup/163208 (defined at home/na/miniconda3/envs/nbsearch-gpu/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node Encoder-Model/Cell-Word-Embedding/embedding_lookup:\n Encoder-Model/Cell-Word-Embedding/embedding_lookup/163208 (defined at home/na/miniconda3/envs/nbsearch-gpu/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\npredict_function -> predict_function\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_387459/1982126474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq2seq_inf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_comments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from sklearn . linear_model import LinearRegression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/codes/NBSearch/end2end/seq2seq.py\u001b[0m in \u001b[0;36mgenerate_comments\u001b[0;34m(self, raw_input_text, max_len_comments)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# get the encoder's features for the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mraw_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpp_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mraw_input_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mcell_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;31m# we want to save the encoder's embedding before its updated by decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m#   because we can use that as an embedding for other tasks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    124\u001b[0m           method.__name__))\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1592\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/miniconda3/envs/nbsearch-gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[0,99] = 1737 is not in [0, 547)\n\t [[node Encoder-Model/Cell-Word-Embedding/embedding_lookup (defined at home/na/codes/NBSearch/end2end/seq2seq.py:223) ]]\n\t [[Encoder-Model/Cell-Word-Embedding/embedding_lookup/_6]]\n  (1) Invalid argument:  indices[0,99] = 1737 is not in [0, 547)\n\t [[node Encoder-Model/Cell-Word-Embedding/embedding_lookup (defined at home/na/codes/NBSearch/end2end/seq2seq.py:223) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_164121]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Encoder-Model/Cell-Word-Embedding/embedding_lookup:\n Encoder-Model/Cell-Word-Embedding/embedding_lookup/163208 (defined at home/na/miniconda3/envs/nbsearch-gpu/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node Encoder-Model/Cell-Word-Embedding/embedding_lookup:\n Encoder-Model/Cell-Word-Embedding/embedding_lookup/163208 (defined at home/na/miniconda3/envs/nbsearch-gpu/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\npredict_function -> predict_function\n"
          ]
        }
      ],
      "source": [
        "seq2seq_inf.generate_comments(\"from sklearn . linear_model import LinearRegression\")[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cRNAn_e0TCMa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following file has been copied data/all_code_embeddings.txt\n",
            "The following file has been copied data/corpus.txt\n",
            "The following file has been copied data/all_markdown_embeddings.txt\n",
            "The following file has been copied data/child_relationships.txt\n",
            "The following file has been copied data/all_code_middle_embeddings.txt\n",
            "The following file has been copied data/train_rows.csv\n",
            "The following file has been copied data/df_test_rows.csv\n",
            "The following file has been copied data/Seq2Seq_pred_comments.csv\n",
            "The following file has been copied data/stored_df.csv\n",
            "The following file has been copied data/predict_rows.csv\n",
            "The following file has been copied data/csv/notebooks_sample.csv\n",
            "The following file has been copied data/sample_data/data/csv/repositories_sample.csv\n",
            "The following file has been copied data/sample_data/data/csv/readmes_sample.csv\n",
            "The following file has been copied data/sample_data/data/csv/notebooks_sample.csv\n",
            "The following file has been copied data/dict.pkl\n",
            "The following file has been copied data/cell_pp.dpkl\n",
            "The following file has been copied data/comments_pp.dpkl\n",
            "The following file has been copied data/lstmattention_seq2seq_model.h5\n",
            "The following file has been copied data/bilstm_seq2seq_model.h5\n",
            "The following file has been copied data/lstm_seq2seq_model.h5\n",
            "The following file has been copied data/gru_seq2seq_model.h5\n"
          ]
        }
      ],
      "source": [
        "def get_files_recursively(start_directory, filter_extension=None):\n",
        "    for root, _, files in os.walk(start_directory):\n",
        "        for file in files:\n",
        "            if filter_extension is None or file.lower().endswith(filter_extension):\n",
        "                yield os.path.join(root, file)\n",
        "\n",
        "def selective_copy(source, target, file_extension=None):\n",
        "    for file in get_files_recursively(source, file_extension):\n",
        "        shutil.copy(file, target)\n",
        "        print(\"The following file has been copied\", file)\n",
        "for extension in ['txt', 'csv', 'pkl', 'h5', 'doc2vec']:\n",
        "  selective_copy(\"data/\",\"resource\", extension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "generate_markdown.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ad5c2e6f9665c6a6e629a72de3f69c68997cd13b2bc7a08d34aff9c6dac85330"
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit ('nbsearch-gpu': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
